{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"model-server Work in Progress gRPC server for hosting Deep Learning models trained on any framework.","title":"Home"},{"location":"#model-server","text":"","title":"model-server"},{"location":"#work-in-progress","text":"gRPC server for hosting Deep Learning models trained on any framework.","title":"Work in Progress"},{"location":"model_server.core/","text":"Source: model_server/core.py#L0 Servable Helper class that provides a standard way to create an ABC using inheritance. Servable. __init__ __init__(self) Abstract base class for custom servables. All custom servables must inherit from this. All custom servables inheriting from this must implement the following methods: predict(self, input_array_dict) get_model_info(self, list_of_model_info_dict) Servable.get_model_info get_model_info(self, list_of_model_info_dict) Abstract method which is responsible for the call GetModelInfo Arguments: list_of_model_info_dict (list/tuple): A list containing model_info_dicts Note: model_info_dict contains the following keys: { \"name\": \"model name as string\" \"version\": \"version as string\" \"status\": \"status string\" \"misc\": \"string with miscellaneous info\" } Returns: list_of_model_info_dict (dict): containing the model and server info. This is similar to the function input Servable.predict predict(self, input_array_dict) Abstract method where the model prediction logic lives. This method is responsible for the gRPC call GetPredictions(). All custom servables must define this method. Arguments: input_array_dict (dict): The PredictionRequest proto decoded as a python dictionary. # example input_array_dict = { \"input_tensor_name1\": numpy array, \"input_tensor_name2\": numpy array } Returns: A python dictionary with key (typically output name) and value as numpy array of predictions # example output = { \"output_tensor_name1\": numpy array, \"output_tensor_name2\": numpy array } ModelServerServicer ModelServerServicer. __init__ __init__(self, custom_servable_object) gRPC Model Server Services. This is where the RPC methods are defined. Arguments: custom_servable_object : custom servable classe's instance ModelServerServicer.GetModelInfo GetModelInfo(self, request, context) Entrypoint for GetModelInfo gRPC call. Uses the get_model_info method defined in custom servable Arguments: request (protobuf): gRPC request containing input ModelInfo protobuf context (protobuf): gRPC context object Returns: ModelInfo protobuf ModelServerServicer.GetPredictions GetPredictions(self, request, context) Entrypoint for GetPredictions gRPC call. Uses the predict method defined in custom servable Arguments: request (protobuf): gRPC request containing input PredictRequest protobuf context (protobuf): gRPC context object Returns: PredictResponse protobuf","title":"Model server.core"},{"location":"model_server.core/#servable","text":"Helper class that provides a standard way to create an ABC using inheritance.","title":"Servable"},{"location":"model_server.core/#servable__init__","text":"__init__(self) Abstract base class for custom servables. All custom servables must inherit from this. All custom servables inheriting from this must implement the following methods: predict(self, input_array_dict) get_model_info(self, list_of_model_info_dict)","title":"Servable.__init__"},{"location":"model_server.core/#servableget_model_info","text":"get_model_info(self, list_of_model_info_dict) Abstract method which is responsible for the call GetModelInfo Arguments: list_of_model_info_dict (list/tuple): A list containing model_info_dicts Note: model_info_dict contains the following keys: { \"name\": \"model name as string\" \"version\": \"version as string\" \"status\": \"status string\" \"misc\": \"string with miscellaneous info\" } Returns: list_of_model_info_dict (dict): containing the model and server info. This is similar to the function input","title":"Servable.get_model_info"},{"location":"model_server.core/#servablepredict","text":"predict(self, input_array_dict) Abstract method where the model prediction logic lives. This method is responsible for the gRPC call GetPredictions(). All custom servables must define this method. Arguments: input_array_dict (dict): The PredictionRequest proto decoded as a python dictionary. # example input_array_dict = { \"input_tensor_name1\": numpy array, \"input_tensor_name2\": numpy array } Returns: A python dictionary with key (typically output name) and value as numpy array of predictions # example output = { \"output_tensor_name1\": numpy array, \"output_tensor_name2\": numpy array }","title":"Servable.predict"},{"location":"model_server.core/#modelserverservicer","text":"","title":"ModelServerServicer"},{"location":"model_server.core/#modelserverservicer__init__","text":"__init__(self, custom_servable_object) gRPC Model Server Services. This is where the RPC methods are defined. Arguments: custom_servable_object : custom servable classe's instance","title":"ModelServerServicer.__init__"},{"location":"model_server.core/#modelserverservicergetmodelinfo","text":"GetModelInfo(self, request, context) Entrypoint for GetModelInfo gRPC call. Uses the get_model_info method defined in custom servable Arguments: request (protobuf): gRPC request containing input ModelInfo protobuf context (protobuf): gRPC context object Returns: ModelInfo protobuf","title":"ModelServerServicer.GetModelInfo"},{"location":"model_server.core/#modelserverservicergetpredictions","text":"GetPredictions(self, request, context) Entrypoint for GetPredictions gRPC call. Uses the predict method defined in custom servable Arguments: request (protobuf): gRPC request containing input PredictRequest protobuf context (protobuf): gRPC context object Returns: PredictResponse protobuf","title":"ModelServerServicer.GetPredictions"},{"location":"model_server.utils.model_info_utils/","text":"Source: model_server/utils/model_info_utils.py#L0 create_model_info_proto create_model_info_proto(list_of_model_info_dict) Creates a ModelInfo proto Arguments: list_of_model_info_dict (list/tuple): A list containing model_info_dicts Note: model_info_dict contains the following keys: { \"name\": \"model name as string\" \"version\": \"version as string\" \"status\": \"status string\" \"misc\": \"string with miscellaneous info\" } Returns: ModelInfo proto decode_model_info_proto decode_model_info_proto(model_info_proto) Decodes the model_info_proto created by create_model_info_proto Arguments: model_info_proto (ModelInfo proto): model_info_proto created by create_model_info_proto Returns: list_of_model_info_dict (list): A list containing model_info_dicts Note: model_info_dict contains the following keys: { \"name\": \"model name as string\" \"version\": \"version as string\" \"status\": \"status string\" \"misc\": \"string with miscellaneous info\" }","title":"Model server.utils.model info utils"},{"location":"model_server.utils.model_info_utils/#create_model_info_proto","text":"create_model_info_proto(list_of_model_info_dict) Creates a ModelInfo proto Arguments: list_of_model_info_dict (list/tuple): A list containing model_info_dicts Note: model_info_dict contains the following keys: { \"name\": \"model name as string\" \"version\": \"version as string\" \"status\": \"status string\" \"misc\": \"string with miscellaneous info\" } Returns: ModelInfo proto","title":"create_model_info_proto"},{"location":"model_server.utils.model_info_utils/#decode_model_info_proto","text":"decode_model_info_proto(model_info_proto) Decodes the model_info_proto created by create_model_info_proto Arguments: model_info_proto (ModelInfo proto): model_info_proto created by create_model_info_proto Returns: list_of_model_info_dict (list): A list containing model_info_dicts Note: model_info_dict contains the following keys: { \"name\": \"model name as string\" \"version\": \"version as string\" \"status\": \"status string\" \"misc\": \"string with miscellaneous info\" }","title":"decode_model_info_proto"},{"location":"model_server.utils.prediction_utils/","text":"Source: model_server/utils/prediction_utils.py#L0 create_predict_request create_predict_request(input_tensorproto_dict, name=None, version=None) Creates a PredictRequest proto Arguments: input_tensorproto_dict (dict): A dictionary with key (typically input tensor name string) and value as TensorProto. name (str): Optional model name. Default None version (str): Optional model version. Default None Returns: PredictRequest proto create_predict_response create_predict_response(output_tensorproto_dict, name=None, version=None) Creates a PredictResponse proto Arguments: input_tensorproto_dict (dict): A dictionary with key (typically output tensor name string) and value as TensorProto. name (str): Optional model name. Default None version (str): Optional model version. Default None Returns: PredictResponse proto","title":"Model server.utils.prediction utils"},{"location":"model_server.utils.prediction_utils/#create_predict_request","text":"create_predict_request(input_tensorproto_dict, name=None, version=None) Creates a PredictRequest proto Arguments: input_tensorproto_dict (dict): A dictionary with key (typically input tensor name string) and value as TensorProto. name (str): Optional model name. Default None version (str): Optional model version. Default None Returns: PredictRequest proto","title":"create_predict_request"},{"location":"model_server.utils.prediction_utils/#create_predict_response","text":"create_predict_response(output_tensorproto_dict, name=None, version=None) Creates a PredictResponse proto Arguments: input_tensorproto_dict (dict): A dictionary with key (typically output tensor name string) and value as TensorProto. name (str): Optional model name. Default None version (str): Optional model version. Default None Returns: PredictResponse proto","title":"create_predict_response"},{"location":"model_server.utils.tensor_utils/","text":"Source: model_server/utils/tensor_utils.py#L0 create_tensor_proto create_tensor_proto(array, shape=None, dtype=None, name=None) Create a TensorProto from numpy array. Arguments: array (np.ndarray): The numpy array to convert to TensorProto shape (tuple): Optional shape of the array to reshape it to. If not given, it is inferred from the numpy array. Default None dtype (str): Optional dtype to convert the array to. Refer tensor.proto for supported datatypes. If not given, it is inferred from the numpy array. Default None. name (str): Optional name for the TensorProto. Default None Returns: A TensorProto containing the given array Note: python strings will be encoded to python bytes. Use dtype = \"object\" if the numpy array contains strings. dtype \"string\" and \"object\" are treated as same. \"string\" is converted to python \"object\". This is because, numpy handles variable length strings in this way create_array_from_proto create_array_from_proto(tensor_proto) Retrive array from TensorProto. Arguments: tensor_proto (TensorProto): An instance of TensorProto Returns: numpy array Note: python strings will be encoded to python bytes. Use dtype = \"object\" if the numpy array contains strings. dtype \"string\" and \"object\" are treated as same. \"string\" is converted to python \"object\". This is because, numpy handles variable length strings in this way","title":"Model server.utils.tensor utils"},{"location":"model_server.utils.tensor_utils/#create_tensor_proto","text":"create_tensor_proto(array, shape=None, dtype=None, name=None) Create a TensorProto from numpy array. Arguments: array (np.ndarray): The numpy array to convert to TensorProto shape (tuple): Optional shape of the array to reshape it to. If not given, it is inferred from the numpy array. Default None dtype (str): Optional dtype to convert the array to. Refer tensor.proto for supported datatypes. If not given, it is inferred from the numpy array. Default None. name (str): Optional name for the TensorProto. Default None Returns: A TensorProto containing the given array Note: python strings will be encoded to python bytes. Use dtype = \"object\" if the numpy array contains strings. dtype \"string\" and \"object\" are treated as same. \"string\" is converted to python \"object\". This is because, numpy handles variable length strings in this way","title":"create_tensor_proto"},{"location":"model_server.utils.tensor_utils/#create_array_from_proto","text":"create_array_from_proto(tensor_proto) Retrive array from TensorProto. Arguments: tensor_proto (TensorProto): An instance of TensorProto Returns: numpy array Note: python strings will be encoded to python bytes. Use dtype = \"object\" if the numpy array contains strings. dtype \"string\" and \"object\" are treated as same. \"string\" is converted to python \"object\". This is because, numpy handles variable length strings in this way","title":"create_array_from_proto"}]}